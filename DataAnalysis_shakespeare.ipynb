{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = \"/usr/local/bin/python3.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "appname = username + '_app'\n",
    "spark = SparkSession.builder.appName(appname).config(\"spark.yarn.queue\", \"default\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('shakespeare.txt', <http.client.HTTPMessage at 0x7f39a90e7320>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(f\"http://www.gutenberg.org/files/100/100-0.txt\", \"shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hadoop fs -put shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "textDf = spark.read.text(\"/user/zaur/shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into lower case\n",
    "from pyspark.sql import functions as F\n",
    "textLowerDf = textDf.select(F.lower(F.col(\"value\")).alias(\"words_lower\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         words_lower|\n",
      "+--------------------+\n",
      "|project gutenberg...|\n",
      "|                    |\n",
      "|this ebook is for...|\n",
      "|most other parts ...|\n",
      "|whatsoever.  you ...|\n",
      "|of the project gu...|\n",
      "|www.gutenberg.org...|\n",
      "|have to check the...|\n",
      "|         this ebook.|\n",
      "|                    |\n",
      "|                    |\n",
      "|title: the comple...|\n",
      "|                    |\n",
      "|author: william s...|\n",
      "|                    |\n",
      "|release date: jan...|\n",
      "|last updated: aug...|\n",
      "|                    |\n",
      "|   language: english|\n",
      "|                    |\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|Project Gutenberg...|\n",
      "|                    |\n",
      "|This eBook is for...|\n",
      "|most other parts ...|\n",
      "|whatsoever.  You ...|\n",
      "|of the Project Gu...|\n",
      "|www.gutenberg.org...|\n",
      "|have to check the...|\n",
      "|         this ebook.|\n",
      "|                    |\n",
      "|                    |\n",
      "|Title: The Comple...|\n",
      "|                    |\n",
      "|Author: William S...|\n",
      "|                    |\n",
      "|Release Date: Jan...|\n",
      "|Last Updated: Aug...|\n",
      "|                    |\n",
      "|   Language: English|\n",
      "|                    |\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textLowerDf.show()\n",
    "textDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- words_lower: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textLowerDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the words of a sentence\n",
    "textSplitDf = textLowerDf.select(F.split(F.col(\"words_lower\"), \" \").alias(\"words_split\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- words_split: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textSplitDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- words_split: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textSplitDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         words_split|\n",
      "+--------------------+\n",
      "|[project, gutenbe...|\n",
      "|                  []|\n",
      "|[this, ebook, is,...|\n",
      "|[most, other, par...|\n",
      "|[whatsoever., , y...|\n",
      "|[of, the, project...|\n",
      "|[www.gutenberg.or...|\n",
      "|[have, to, check,...|\n",
      "|      [this, ebook.]|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|[title:, the, com...|\n",
      "|                  []|\n",
      "|[author:, william...|\n",
      "|                  []|\n",
      "|[release, date:, ...|\n",
      "|[last, updated:, ...|\n",
      "|                  []|\n",
      "|[language:, english]|\n",
      "|                  []|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textSplitDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "textExplodedDf = textSplitDf.select(F.explode(F.col(\"words_split\")).alias(\"word\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|        word|\n",
      "+------------+\n",
      "|     project|\n",
      "| gutenberg’s|\n",
      "|         the|\n",
      "|    complete|\n",
      "|       works|\n",
      "|          of|\n",
      "|     william|\n",
      "|shakespeare,|\n",
      "|          by|\n",
      "|     william|\n",
      "| shakespeare|\n",
      "|            |\n",
      "|        this|\n",
      "|       ebook|\n",
      "|          is|\n",
      "|         for|\n",
      "|         the|\n",
      "|         use|\n",
      "|          of|\n",
      "|      anyone|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textExplodedDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "textExplodedDf = textExplodedDf.where(F.ltrim(F.col(\"word\")) != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|        word|\n",
      "+------------+\n",
      "|     project|\n",
      "| gutenberg’s|\n",
      "|         the|\n",
      "|    complete|\n",
      "|       works|\n",
      "|          of|\n",
      "|     william|\n",
      "|shakespeare,|\n",
      "|          by|\n",
      "|     william|\n",
      "| shakespeare|\n",
      "|        this|\n",
      "|       ebook|\n",
      "|          is|\n",
      "|         for|\n",
      "|         the|\n",
      "|         use|\n",
      "|          of|\n",
      "|      anyone|\n",
      "|    anywhere|\n",
      "+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textExplodedDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "textExplodedDf = textExplodedDf.select(F.regexp_extract(F.col(\"word\"), \"[a-z]+\", 0).alias(\"word\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       word|\n",
      "+-----------+\n",
      "|    project|\n",
      "|  gutenberg|\n",
      "|        the|\n",
      "|   complete|\n",
      "|      works|\n",
      "|         of|\n",
      "|    william|\n",
      "|shakespeare|\n",
      "|         by|\n",
      "|    william|\n",
      "|shakespeare|\n",
      "|       this|\n",
      "|      ebook|\n",
      "|         is|\n",
      "|        for|\n",
      "|        the|\n",
      "|        use|\n",
      "|         of|\n",
      "|     anyone|\n",
      "|   anywhere|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textExplodedDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "textWordCounts = textExplodedDf.groupBy(\"word\").count().orderBy(F.col(\"count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the|30207|\n",
      "| and|28402|\n",
      "|   i|23870|\n",
      "|  to|21274|\n",
      "|  of|18833|\n",
      "|   a|16266|\n",
      "| you|14676|\n",
      "|  my|13180|\n",
      "|  in|12347|\n",
      "|that|12225|\n",
      "|  is| 9912|\n",
      "| not| 9078|\n",
      "|with| 8537|\n",
      "|  me| 8285|\n",
      "| for| 8283|\n",
      "|  it| 8234|\n",
      "| his| 7583|\n",
      "|  be| 7407|\n",
      "|  he| 7280|\n",
      "|this| 7184|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textWordCounts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('stopwords.txt', <http.client.HTTPMessage at 0x7f39a92cd9b0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(f\"https://raw.githubusercontent.com/farooq-teqniqly/blog-pyspark-for-noobs-part-2/master/stopwords.txt\", \"stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmr: DEPRECATED: Please use '-rm -r' instead.\n",
      "Deleted stopwords.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rmr stopwords.txt\n",
    "!hadoop fs -put stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsDf = (spark.read.text(\"/user/zaur/stopwords.txt\")\n",
    "                .select(F.lower(F.col(\"value\")).alias(\"words_lower\"))\n",
    "                .select(F.rtrim(F.col(\"words_lower\")).alias(\"word\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "textWordCounts = textWordCounts.join(stopWordsDf, \"word\",  \"leftanti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textWordCounts.where(F.col(\"word\") == \"able\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a's\n",
      "able\n",
      "about\n",
      "above\n",
      "according\n",
      "accordingly\n",
      "across\n",
      "actually\n",
      "after\n",
      "afterwards\n",
      "again\n",
      "against\n",
      "ain't\n",
      "all\n",
      "allow\n",
      "allows\n",
      "almost\n",
      "alone\n",
      "along\n",
      "already\n",
      "also\n",
      "although\n",
      "always\n",
      "am\n",
      "among\n",
      "amongst\n",
      "an\n",
      "and\n",
      "another\n",
      "any\n",
      "anybody\n",
      "anyhow\n",
      "anyone\n",
      "anything\n",
      "anyway\n",
      "anyways\n",
      "anywhere\n",
      "apart\n",
      "appear\n",
      "appreciate\n",
      "appropriate\n",
      "are\n",
      "aren't\n",
      "around\n",
      "as\n",
      "aside\n",
      "ask\n",
      "asking\n",
      "associated\n",
      "at\n",
      "available\n",
      "away\n",
      "awfully\n",
      "b\n",
      "be\n",
      "became\n",
      "because\n",
      "become\n",
      "becomes\n",
      "becoming\n",
      "been\n",
      "before\n",
      "beforehand\n",
      "behind\n",
      "being\n",
      "believe\n",
      "below\n",
      "beside\n",
      "besides\n",
      "best\n",
      "better\n",
      "between\n",
      "beyond\n",
      "both\n",
      "brief\n",
      "but\n",
      "by\n",
      "c\n",
      "c'mon\n",
      "c's\n",
      "came\n",
      "can\n",
      "can't\n",
      "cannot\n",
      "cant\n",
      "cause\n",
      "causes\n",
      "certain\n",
      "certainly\n",
      "changes\n",
      "clearly\n",
      "co\n",
      "com\n",
      "come\n",
      "comes\n",
      "concerning\n",
      "consequently\n",
      "consider\n",
      "considering\n",
      "contain\n",
      "containing\n",
      "contains\n",
      "corresponding\n",
      "could\n",
      "couldn't\n",
      "course\n",
      "currently\n",
      "d\n",
      "definitely\n",
      "described\n",
      "despite\n",
      "did\n",
      "didn't\n",
      "different\n",
      "do\n",
      "does\n",
      "doesn't\n",
      "doing\n",
      "don't\n",
      "done\n",
      "down\n",
      "downwards\n",
      "during\n",
      "e\n",
      "each\n",
      "edu\n",
      "eg\n",
      "eight\n",
      "either\n",
      "else\n",
      "elsewhere\n",
      "enough\n",
      "entirely\n",
      "especially\n",
      "et\n",
      "etc\n",
      "even\n",
      "ever\n",
      "every\n",
      "everybody\n",
      "everyone\n",
      "everything\n",
      "everywhere\n",
      "ex\n",
      "exactly\n",
      "example\n",
      "except\n",
      "f\n",
      "far\n",
      "few\n",
      "fifth\n",
      "first\n",
      "five\n",
      "followed\n",
      "following\n",
      "follows\n",
      "for\n",
      "former\n",
      "formerly\n",
      "forth\n",
      "four\n",
      "from\n",
      "further\n",
      "furthermore\n",
      "g\n",
      "get\n",
      "gets\n",
      "getting\n",
      "given\n",
      "gives\n",
      "go\n",
      "goes\n",
      "going\n",
      "gone\n",
      "got\n",
      "gotten\n",
      "greetings\n",
      "h\n",
      "had\n",
      "hadn't\n",
      "happens\n",
      "hardly\n",
      "has\n",
      "hasn't\n",
      "have\n",
      "haven't\n",
      "having\n",
      "he\n",
      "he's\n",
      "hello\n",
      "help\n",
      "hence\n",
      "her\n",
      "here\n",
      "here's\n",
      "hereafter\n",
      "hereby\n",
      "herein\n",
      "hereupon\n",
      "hers\n",
      "herself\n",
      "hi\n",
      "him\n",
      "himself\n",
      "his\n",
      "hither\n",
      "hopefully\n",
      "how\n",
      "howbeit\n",
      "however\n",
      "i\n",
      "i'd\n",
      "i'll\n",
      "i'm\n",
      "i've\n",
      "ie\n",
      "if\n",
      "ignored\n",
      "immediate\n",
      "in\n",
      "inasmuch\n",
      "inc\n",
      "indeed\n",
      "indicate\n",
      "indicated\n",
      "indicates\n",
      "inner\n",
      "insofar\n",
      "instead\n",
      "into\n",
      "inward\n",
      "is\n",
      "isn't\n",
      "it\n",
      "it'd\n",
      "it'll\n",
      "it's\n",
      "its\n",
      "itself\n",
      "j\n",
      "just\n",
      "k\n",
      "keep\n",
      "keeps\n",
      "kept\n",
      "know\n",
      "knows\n",
      "known\n",
      "l\n",
      "last\n",
      "lately\n",
      "later\n",
      "latter\n",
      "latterly\n",
      "least\n",
      "less\n",
      "lest\n",
      "let\n",
      "let's\n",
      "like\n",
      "liked\n",
      "likely\n",
      "little\n",
      "look\n",
      "looking\n",
      "looks\n",
      "ltd\n",
      "m\n",
      "mainly\n",
      "many\n",
      "may\n",
      "maybe\n",
      "me\n",
      "mean\n",
      "meanwhile\n",
      "merely\n",
      "might\n",
      "more\n",
      "moreover\n",
      "most\n",
      "mostly\n",
      "much\n",
      "must\n",
      "my\n",
      "myself\n",
      "n\n",
      "name\n",
      "namely\n",
      "nd\n",
      "near\n",
      "nearly\n",
      "necessary\n",
      "need\n",
      "needs\n",
      "neither\n",
      "never\n",
      "nevertheless\n",
      "new\n",
      "next\n",
      "nine\n",
      "no\n",
      "nobody\n",
      "non\n",
      "none\n",
      "noone\n",
      "nor\n",
      "normally\n",
      "not\n",
      "nothing\n",
      "novel\n",
      "now\n",
      "nowhere\n",
      "o\n",
      "obviously\n",
      "of\n",
      "off\n",
      "often\n",
      "oh\n",
      "ok\n",
      "okay\n",
      "old\n",
      "on\n",
      "once\n",
      "one\n",
      "ones\n",
      "only\n",
      "onto\n",
      "or\n",
      "other\n",
      "others\n",
      "otherwise\n",
      "ought\n",
      "our\n",
      "ours\n",
      "ourselves\n",
      "out\n",
      "outside\n",
      "over\n",
      "overall\n",
      "own\n",
      "p\n",
      "particular\n",
      "particularly\n",
      "per\n",
      "perhaps\n",
      "placed\n",
      "please\n",
      "plus\n",
      "possible\n",
      "presumably\n",
      "probably\n",
      "provides\n",
      "q\n",
      "que\n",
      "quite\n",
      "qv\n",
      "r\n",
      "rather\n",
      "rd\n",
      "re\n",
      "really\n",
      "reasonably\n",
      "regarding\n",
      "regardless\n",
      "regards\n",
      "relatively\n",
      "respectively\n",
      "right\n",
      "s\n",
      "said\n",
      "same\n",
      "saw\n",
      "say\n",
      "saying\n",
      "says\n",
      "second\n",
      "secondly\n",
      "see\n",
      "seeing\n",
      "seem\n",
      "seemed\n",
      "seeming\n",
      "seems\n",
      "seen\n",
      "self\n",
      "selves\n",
      "sensible\n",
      "sent\n",
      "serious\n",
      "seriously\n",
      "seven\n",
      "several\n",
      "shall\n",
      "she\n",
      "should\n",
      "shouldn't\n",
      "since\n",
      "six\n",
      "so\n",
      "some\n",
      "somebody\n",
      "somehow\n",
      "someone\n",
      "something\n",
      "sometime\n",
      "sometimes\n",
      "somewhat\n",
      "somewhere\n",
      "soon\n",
      "sorry\n",
      "specified\n",
      "specify\n",
      "specifying\n",
      "still\n",
      "sub\n",
      "such\n",
      "sup\n",
      "sure\n",
      "t\n",
      "t's\n",
      "take\n",
      "taken\n",
      "tell\n",
      "tends\n",
      "th\n",
      "than\n",
      "thank\n",
      "thanks\n",
      "thanx\n",
      "that\n",
      "that's\n",
      "thats\n",
      "the\n",
      "their\n",
      "theirs\n",
      "them\n",
      "themselves\n",
      "then\n",
      "thence\n",
      "there\n",
      "there's\n",
      "thereafter\n",
      "thereby\n",
      "therefore\n",
      "therein\n",
      "theres\n",
      "thereupon\n",
      "these\n",
      "they\n",
      "they'd\n",
      "they'll\n",
      "they're\n",
      "they've\n",
      "think\n",
      "third\n",
      "this\n",
      "thorough\n",
      "thoroughly\n",
      "those\n",
      "though\n",
      "three\n",
      "through\n",
      "throughout\n",
      "thru\n",
      "thus\n",
      "to\n",
      "together\n",
      "too\n",
      "took\n",
      "toward\n",
      "towards\n",
      "tried\n",
      "tries\n",
      "truly\n",
      "try\n",
      "trying\n",
      "twice\n",
      "two\n",
      "u\n",
      "un\n",
      "under\n",
      "unfortunately\n",
      "unless\n",
      "unlikely\n",
      "until\n",
      "unto\n",
      "up\n",
      "upon\n",
      "us\n",
      "use\n",
      "used\n",
      "useful\n",
      "uses\n",
      "using\n",
      "usually\n",
      "uucp\n",
      "v\n",
      "value\n",
      "various\n",
      "very\n",
      "via\n",
      "viz\n",
      "vs\n",
      "w\n",
      "want\n",
      "wants\n",
      "was\n",
      "wasn't\n",
      "way\n",
      "we\n",
      "we'd\n",
      "we'll\n",
      "we're\n",
      "we've\n",
      "welcome\n",
      "well\n",
      "went\n",
      "were\n",
      "weren't\n",
      "what\n",
      "what's\n",
      "whatever\n",
      "when\n",
      "whence\n",
      "whenever\n",
      "where\n",
      "where's\n",
      "whereafter\n",
      "whereas\n",
      "whereby\n",
      "wherein\n",
      "whereupon\n",
      "wherever\n",
      "whether\n",
      "which\n",
      "while\n",
      "whither\n",
      "who\n",
      "who's\n",
      "whoever\n",
      "whole\n",
      "whom\n",
      "whose\n",
      "why\n",
      "will\n",
      "willing\n",
      "wish\n",
      "with\n",
      "within\n",
      "without\n",
      "won't\n",
      "wonder\n",
      "would\n",
      "would\n",
      "wouldn't\n",
      "x\n",
      "y\n",
      "yes\n",
      "yet\n",
      "you\n",
      "you'd\n",
      "you'll\n",
      "you're\n",
      "you've\n",
      "your\n",
      "yours\n",
      "yourself\n",
      "yourselves\n",
      "z\n",
      "zero"
     ]
    }
   ],
   "source": [
    "!cat stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
